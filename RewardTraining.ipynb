{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7b47d6-047c-4075-862a-4e75cb3d25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer,TrainingArguments\n",
    "from trl import RewardTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf32bf4-593f-4050-adb0-abe6a4da83b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0  <bos><start_of_turn>user\\nBLUELAND is a make-b...   \n",
      "1  <bos><start_of_turn>user\\nBLUELAND is a make-b...   \n",
      "2  <bos><start_of_turn>user\\nBLUELAND is a make-b...   \n",
      "3  <bos><start_of_turn>user\\nBLUELAND is a make-b...   \n",
      "4  <bos><start_of_turn>user\\nBLUELAND is a make-b...   \n",
      "\n",
      "                                          completion  label  \n",
      "0  <bos><start_of_turn>user\\nBLUELAND is a make-b...   True  \n",
      "1  <bos><start_of_turn>user\\nBLUELAND is a make-b...   True  \n",
      "2  <bos><start_of_turn>user\\nBLUELAND is a make-b...   True  \n",
      "3  <bos><start_of_turn>user\\nBLUELAND is a make-b...   True  \n",
      "4  <bos><start_of_turn>user\\nBLUELAND is a make-b...   True  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('missionData_llm.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e6e971-eda2-4019-99ab-13e7502b4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_lst = df['completion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02bd0602-eefe-45a6-a383-9c62e02aedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns=['chosen_response', 'rejected_response'])\n",
    "chosen_lst = []\n",
    "rejected_lst = [] \n",
    "\n",
    "for i in range(50): \n",
    "    chosen_lst.append(completion_lst[i])\n",
    "    rejected_lst.append(completion_lst[i+50])\n",
    "\n",
    "new_df['chosen_response'] = chosen_lst\n",
    "new_df['rejected_response'] = rejected_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e2f9b72-7df2-4506-9dd5-84f44970c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     chosen_response  \\\n",
      "0  <bos><start_of_turn>user\\nBLUELAND is a make-b...   \n",
      "1  <bos><start_of_turn>user\\nBLUELAND is a make-b...   \n",
      "2  <bos><start_of_turn>user\\nBLUELAND is a make-b...   \n",
      "3  <bos><start_of_turn>user\\nBLUELAND is a make-b...   \n",
      "4  <bos><start_of_turn>user\\nBLUELAND is a make-b...   \n",
      "\n",
      "                                   rejected_response  \n",
      "0  <bos><start_of_turn>user\\nBLUELAND is a make-b...  \n",
      "1  <bos><start_of_turn>user\\nBLUELAND is a make-b...  \n",
      "2  <bos><start_of_turn>user\\nBLUELAND is a make-b...  \n",
      "3  <bos><start_of_turn>user\\nBLUELAND is a make-b...  \n",
      "4  <bos><start_of_turn>user\\nBLUELAND is a make-b...  \n"
     ]
    }
   ],
   "source": [
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8cdd8b-b60d-4e0f-8300-529c18472b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Select a base model whch we need to train for reward modeling.\n",
    "model_name = \"distilroberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34f53255-dc90-44a3-b562-c5362257758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(row):\n",
    "    kwargs = {\"padding\": \"max_length\", \"truncation\": True, \"max_length\": 512, \"return_tensors\": \"pt\"}\n",
    "    prompt_plus_chosen_response = row[\"chosen_response\"]\n",
    "    prompt_plus_rejected_response = row[\"rejected_response\"]\n",
    "    tokens_chosen = tokenizer.encode_plus(prompt_plus_chosen_response, **kwargs)\n",
    "    tokens_rejected = tokenizer.encode_plus(prompt_plus_rejected_response, **kwargs)\n",
    "    return {\n",
    "        \"input_ids_chosen\": tokens_chosen[\"input_ids\"][0], \"attention_mask_chosen\": tokens_chosen[\"attention_mask\"][0],\n",
    "        \"input_ids_rejected\": tokens_rejected[\"input_ids\"][0], \"attention_mask_rejected\": tokens_rejected[\"attention_mask\"][0]\n",
    "    }\n",
    "    \n",
    "formatted_dataset = new_df.apply(formatting_func, axis=1)\n",
    "formatted_dataset = pd.DataFrame(list(formatted_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fac9dec-615c-474b-9688-9657028c640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids_chosen           [tensor(0), tensor(41552), tensor(31957), tens...\n",
      "attention_mask_chosen      [tensor(1), tensor(1), tensor(1), tensor(1), t...\n",
      "input_ids_rejected         [tensor(0), tensor(41552), tensor(31957), tens...\n",
      "attention_mask_rejected    [tensor(1), tensor(1), tensor(1), tensor(1), t...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(formatted_df.iloc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11028912-3c81-40a4-98bc-a6ef369e7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "formatted_dict = {\n",
    "    'input_ids_chosen': formatted_df['input_ids_chosen'].tolist(), \n",
    "    'attention_mask_chosen': formatted_df['attention_mask_chosen'].tolist(), \n",
    "    'input_ids_rejected': formatted_df['input_ids_rejected'].tolist(), \n",
    "    'attention_mask_rejected': formatted_df['attention_mask_rejected'].tolist()\n",
    "}\n",
    "formatted_dataset = Dataset.from_dict(formatted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "258235fa-1bd7-4e19-b7f8-ca5578de1a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'],\n",
      "    num_rows: 50\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(formatted_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9518976-fe55-4647-94a8-87ff5dc6c9ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR API key must be 40 characters long, yours was 4\n",
      "wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Development (UC)\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Development (UC)\\Desktop\\kailin\\Review2\\wandb\\run-20240612_162501-1if4ipfl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nus-pkailin/huggingface/runs/1if4ipfl' target=\"_blank\">./reward_model</a></strong> to <a href='https://wandb.ai/nus-pkailin/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nus-pkailin/huggingface' target=\"_blank\">https://wandb.ai/nus-pkailin/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nus-pkailin/huggingface/runs/1if4ipfl' target=\"_blank\">https://wandb.ai/nus-pkailin/huggingface/runs/1if4ipfl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 06:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.680200</td>\n",
       "      <td>0.690945</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.680500</td>\n",
       "      <td>0.687322</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.673500</td>\n",
       "      <td>0.682573</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.673186</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.654999</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.638300</td>\n",
       "      <td>0.621660</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.646700</td>\n",
       "      <td>0.557899</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.566200</td>\n",
       "      <td>0.450677</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.535200</td>\n",
       "      <td>0.327528</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.205484</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.110520</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.054652</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=0.23976782320532947, metrics={'train_runtime': 592.9194, 'train_samples_per_second': 0.624, 'train_steps_per_second': 0.051, 'total_flos': 0.0, 'train_loss': 0.23976782320532947, 'epoch': 10.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dataset = formatted_dataset.train_test_split()\n",
    "# Configuring the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./reward_model\",\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    num_train_epochs = 10,\n",
    "    report_to=None,\n",
    ")\n",
    "\n",
    "# Loading the RewardTrainer from TRL\n",
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=formatted_dataset[\"train\"],\n",
    "    eval_dataset=formatted_dataset[\"test\"],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b15d2bf-4fad-4816-bca9-1914397b4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./rewardmodel1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b441288-99f9-4d21-b234-f6a5f9762e51",
   "metadata": {},
   "source": [
    "Source Code: https://medium.com/towards-generative-ai/reward-model-training-2209d1befb5f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbdd43d-f963-498d-a71f-6767d86cbe9f",
   "metadata": {},
   "source": [
    "**MODEL INFERENCE TEST 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d9b9ab7-57f6-477a-b4e1-83f74656b881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7235fdeb5938488bafce0632ae63505a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import KTOConfig, KTOTrainer, ModelConfig, get_peft_config, setup_chat_format\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-1.1-7b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-1.1-7b-it\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbb8edca-cba9-4dfc-a3ae-ad10653fb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "BLUELAND is a make-believe country. REDLAND is another make-believe country, an enemy of BLUELAND. \n",
    "\n",
    "Write me a training scenario for an air strike mission by BLUELAND to destroy a specified target. This scenario will be given to BLUELAND, who will devise a strategy to execute the plan. The scenario should be non-descriptive, concise and factual. The information should be sufficient to help BLUELAND to decide their loadout and strategy. The scenario should include the following information about the target and REDLAND: \n",
    "1.\tCommander’s Intent: Captures the broad mission objectives (eg: 100% TOT, 50% BLUELAND losses, 100% REDLAND destruction, destroy bunkers, etc)\n",
    "2.\tForce Composition: REDLAND’s units and objects participating in the scenario, Order of Battle, i.e the identification, strength, command structure, disposition for the personnel, units, equipment of any military force, command & control hierarchies, communication networks and communication channels. This should be specific, i.e exact model of aircraft or missiles (eg: F-15 fighter jets, SA-7 surface-to-air missile launchers, ZSU-23-4 Shilka self-propelled anti-aircraft gun systems, etc). \n",
    "3.\tGeography: Distance to target and distance to REDLAND threats. Specification of environmental conditions which are of interest (eg: day/night/dawn, buildings, vegetation, ditches in surroundings, etc) \n",
    "4.\tSurrounding Conditions: Overview of all scenario-related information of interest, i.e surrounding military situation, REDLAND readiness state, etc.\n",
    "5.\tTarget(s) Details:  Any relevant information about target(s), i.e type and number of targets. \n",
    "6.\tRules of Engagement: Directives that outline when and how BLUELAND can engage hostile forces.\n",
    "\"\"\"\n",
    "\n",
    "prompt_dict = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "prompt = tokenizer.apply_chat_template(prompt_dict, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "positive_response = \"\"\"\"## Training Scenario: Operation Azure Strike\n",
    "\n",
    "**Commander’s Intent:**\n",
    "- Neutralize the enemy's coastal defense installations. Disable radar systems and destroy ammunition depots.\n",
    "- Ensure 100% accuracy in missile strikes.\n",
    "- Limit BLUELAND Navy losses to a maximum of 30%.\n",
    "- Achieve complete destruction of REDLAND Navy vessels.\n",
    "\n",
    "**Force Composition:**\n",
    "- REDLAND Navy: Three K300P Bastion-P coastal defense missile systems and two 9K33 Osa surface-to-air missile systems.\n",
    "- REDLAND Coastal Forces: 200 troops stationed at the installations, armed with small arms and light anti-aircraft weapons. No known armored vehicles.\n",
    "\n",
    "**Geography:**\n",
    "- Distance to REDLAND threats: Coastal Defense Installations: 5 km west of the target area. Radar Systems: 10 km south of the target. Ammunition Depots: 3 km north of the target.\n",
    "- Environmental Conditions: Daytime mission, clear skies with visibility up to 10 km. Target located along the coastline with open terrain.\n",
    "\n",
    "**Surrounding Conditions:**\n",
    "- REDLAND Navy is conducting patrols in the vicinity, with increased activity observed along the coast.\n",
    "- REDLAND Coastal Forces are on heightened alert, monitoring the coastline for any suspicious activity.\n",
    "- BLUELAND's reconnaissance indicates recent upgrades to REDLAND's coastal defense systems, but details on the extent are limited.\n",
    "\n",
    "**Target(s) Details:**\n",
    "- Coastal defense installations consist of three main sites: missile launch pads, radar installations, and ammunition depots.\n",
    "- Installations are fortified with concrete bunkers and sandbag emplacements.\n",
    "- Radar systems are housed in reinforced shelters with overhead protection.\n",
    "\n",
    "**Rules of Engagement:**\n",
    "- REDLAND forces are deemed hostile and will engage any perceived threat.\n",
    "- BLUELAND forces are authorized to engage targets defensively and preemptively neutralize any imminent threats.\n",
    "- Priority is given to military targets, with measures taken to minimize collateral damage to civilian infrastructure.\n",
    "\"\"\"\n",
    "\n",
    "positive_response = prompt + positive_response + \"<eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11913e2b-030d-46a8-9be3-a2b50dd5aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_response = \"\"\"\"## Training Scenario: Operation Azure Strike\n",
    "\n",
    "**Commander’s Intent:**\n",
    "- Disrupt enemy agriculture to cause economic strain and food shortages.\n",
    "- Create civil unrest and undermine confidence in REDLAND authorities.\n",
    "\n",
    "**Force Composition:**\n",
    "- REDLAND Civil Defense: Local police units and militia groups patrolling rural areas. Strength and equipment unknown.\n",
    "- REDLAND Agricultural Ministry: Workers and technicians responsible for irrigation maintenance.\n",
    "\n",
    "**Geography:**\n",
    "- Target: Widespread agricultural areas throughout rural districts.\n",
    "- Environmental Conditions: Daytime operation in farmland with scattered villages.\n",
    "\n",
    "**Surrounding Conditions:**\n",
    "- REDLAND security forces on alert due to recent civil unrest.\n",
    "- Risk of civilian informants reporting suspicious activities.\n",
    "\n",
    "**Target(s) Details:**\n",
    "- Agricultural infrastructure: Canals, pipelines, and pumping stations critical for irrigation.\n",
    "\n",
    "**Rules of Engagement:**\n",
    "- Minimize civilian casualties and avoid direct confrontation.\n",
    "- Focus on infrastructure sabotage while evading detection.\n",
    "- Convert actions to maintain plausible deniability and prevent escalation.\"\"\"\n",
    "\n",
    "negative_response = prompt + negative_response + \"<eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30cccd97-2245-4ac1-ac6a-d771238e6044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.641488552093506\n",
      "-3.4891982078552246\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(\"./rewardmodel1\")\n",
    "\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\"./rewardmodel1\")\n",
    "\n",
    "def get_score(model, tokenizer, response):\n",
    "    # Tokenize the input sequences\n",
    "    inputs = tokenizer.encode_plus(response, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "    # Perform forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract the logits\n",
    "    logits = outputs.logits\n",
    "\n",
    "    return logits.item()\n",
    "\n",
    "# Example usage\n",
    "score = get_score(reward_model, reward_tokenizer, positive_response)\n",
    "print(score)\n",
    "\n",
    "score = get_score(reward_model, reward_tokenizer, negative_response)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d8eac8-6049-48cf-90eb-373acff07a51",
   "metadata": {},
   "source": [
    "**MODEL INFERENCE TEST 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7eb8d6b-95a9-4c84-91db-37bee6beb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_response = \"\"\"\"## Training Scenario: Operation Azure Thunder\n",
    "\n",
    "**Commander’s Intent:**\n",
    "- Neutralize enemy air defenses and radar installations.\n",
    "- Destroy ammunition depots and fuel storage facilities.\n",
    "- Provide air support for ground operations.\n",
    "\n",
    "**Force Composition:**\n",
    "- BLUELAND Air Force: F-15 fighter jets armed with precision-guided munitions, supported by A-10 Warthog ground attack aircraft.\n",
    "- BLUELAND Ground Forces: Special Forces teams tasked with securing high-value targets and conducting close air support operations.\n",
    "\n",
    "**Geography:**\n",
    "- Distance to REDLAND threats: SAM sites: 5 km northwest of the target, Radar installations: 10 km northeast of the target.\n",
    "- Environmental Conditions: Daytime mission with clear skies and good visibility. Target area is a mix of urban and rural terrain.\n",
    "\n",
    "**Surrounding Conditions:**\n",
    "- REDLAND's Air Force is moderately active in the area, with occasional patrols.\n",
    "- REDLAND's ground forces are concentrated in defensive positions to the east but are not directly engaging BLUELAND forces.\n",
    "- BLUELAND's intelligence indicates moderate enemy air defense capabilities but no advanced fighter aircraft.\n",
    "\n",
    "**Target(s) Details:**\n",
    "- Enemy air defense sites, radar installations, ammunition depots, and fuel storage facilities located within a designated engagement zone.\n",
    "\n",
    "**Rules of Engagement:**\n",
    "- Engage hostile forces only within the defined engagement zone.\n",
    "- Minimize civilian casualties and collateral damage to infrastructure.\n",
    "- Maintain air superiority to support ongoing ground operations.\"\"\"\n",
    "\n",
    "positive_response = prompt + positive_response + \"<eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8197cfc-500d-4137-8b82-91033a0e7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_response = \"\"\"\"## Training Scenario: Operation Azure Strike\n",
    "\n",
    "**Commander’s Intent:**\n",
    "- Conduct reconnaissance of enemy positions and movements.\n",
    "- Disrupt enemy supply lines and communication networks.\n",
    "- Gather intelligence on enemy troop movements and defensive fortifications.\n",
    "\n",
    "**Force Composition:**\n",
    "- REDLAND Military: Mix of infantry units and armored vehicles, estimated at battalion strength. Armament includes small arms, light artillery, and armored personnel carriers.\n",
    "\n",
    "**Geography:**\n",
    "- Target: Rural villages and agricultural areas along the border region.\n",
    "- Environmental Conditions: Nighttime operation with limited visibility due to fog and low clouds.\n",
    "\n",
    "**Surrounding Conditions:**\n",
    "- Moderate enemy presence in the area but limited air defense capabilities.\n",
    "- Sparse civilian population in the target area, primarily farmers and villagers.\n",
    "\n",
    "**Target(s) Details:**\n",
    "- Enemy supply convoys, communication relay points, and forward operating bases located in rural areas.\n",
    "\n",
    "**Rules of Engagement:**\n",
    "- Avoid direct engagement with enemy forces unless absolutely necessary.\n",
    "- Conduct hit-and-run tactics to disrupt enemy operations without risking significant casualties.\n",
    "- Extract intelligence on enemy troop movements and defensive positions for future operations.\"\"\"\n",
    "\n",
    "negative_response = prompt + negative_response + \"<eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1877a1fc-15fc-4b72-85c8-fa2a2914c5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.111926317214966\n",
      "-3.2461066246032715\n"
     ]
    }
   ],
   "source": [
    "score = get_score(reward_model, reward_tokenizer, positive_response)\n",
    "print(score)\n",
    "\n",
    "score = get_score(reward_model, reward_tokenizer, negative_response)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f9929-0095-424f-a9ed-5c07bd2087a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
